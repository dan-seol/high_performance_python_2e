{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Asynchronous I/O\n",
    "## Shared CPU--I/O Workload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- will create another toy problem\n",
    "    - which we have a CPU-bound problem that needs to communicate frequently with a database to save results\n",
    "    - CPU workload can be anything\n",
    "        - e.g.) take bcrypt hash of a random string with larger and larger workload factors to increase the amount of CPU-bound work\n",
    "    - represents any sort of problem in which a program has heavy calculations to do, and\n",
    "    - the results must be stored in a database, potentially with a hravy I/O penalty\n",
    "- restrictions\n",
    "    - it has an HTTP API\n",
    "    - response time are on the order of 100 ms\n",
    "    - database can satisfy many requests at a time\n",
    "- the database response time is deliberately chosen to be higher than usual\n",
    "\n",
    "|Difficulty parameter|8|10|11|12|\n",
    "|---|---|---|---|---|\n",
    "|Search per iteration|0.0156|0.0623|0.1244|0.2487|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import string\n",
    "import bcrypt\n",
    "import requests\n",
    "import asyncio\n",
    "import aiohttp\n",
    "\n",
    "UTF_8 = \"utf8\"\n",
    "URL = \"http://127.0.0.1:8080/add\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- some simple code that calculates the `bcrypt` hash of a string and makes a request to the database's http API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def do_task(difficulty):\n",
    "    \"\"\"\n",
    "    Hash a number 10 character string using bcrypt\n",
    "    with a specified difficulty rating\n",
    "    \"\"\"\n",
    "    # we generate a random 10-char byte array\n",
    "    password = (\"\".join(random.sample(string.ascii_lowercase, 10))\n",
    "                .encode(UTF_8))\n",
    "    # the difficulty parameter sets how hard it is to generate the password\n",
    "    # by increasing the CPU and memory requirements of the hashing algorithm\n",
    "    salt = bcrypt.gensalt(difficulty)\n",
    "    result = bcrypt.hashpw(password, salt)\n",
    "    return result.decode(UTF_8)\n",
    "\n",
    "\n",
    "def save_result_serial(result):\n",
    "    url = URL\n",
    "    response = requests.post(url, data=result)\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def calculate_task_serial(num_iter, task_difficulty):\n",
    "    for _ in range(num_iter):\n",
    "        result = do_task(task_difficulty)\n",
    "        save_result_serial(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batched Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AsyncBatcher(object):\n",
    "    def __init__(self, batch_size) -> None:\n",
    "        self.batch_size = batch_size\n",
    "        self.batch = []\n",
    "        self.client_session = None\n",
    "        self.url = URL\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args, **kwargs):\n",
    "        self.flush()\n",
    "\n",
    "    def save(self, result):\n",
    "        self.batch.append(result)\n",
    "        if len(self.batch) == self.batch_size:\n",
    "            self.flush()\n",
    "\n",
    "    def flush(self):\n",
    "        loop = asyncio.get_event_loop()\n",
    "        loop.run_until_complete(self.__aflush()) # we can start up an event loop just to run a single async function\n",
    "\n",
    "    async def __aflush(self):\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            tasks = tuple(self.fetch(result, session) for result in self.batch)\n",
    "            for task in asyncio.as_completed(tasks):\n",
    "                await task\n",
    "        self.batch.clear()\n",
    "\n",
    "    async def fetch(self, result, session):\n",
    "        async with session.post(self.url, data=result) as response:\n",
    "            return await response.json()\n",
    "\n",
    "def calculate_task_batch(num_iter, task_difficulty):\n",
    "    with AsyncBatcher(100) as batcher:\n",
    "        for _ in range(num_iter):\n",
    "            result = do_task(task_difficulty)\n",
    "            batcher.save(result)\n",
    "        batcher.flush()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- runtime for difficulty=8 was brought down to 10.21 seconds\n",
    "- 6.95 times speed-up\n",
    "- if the db has infinite throughput, we can take advantage that we get only 100 ms penalty when `AsyncBatcher` is full and does a flush\n",
    "    - best performance is obtained by just saving all the requests to the db\n",
    "- in reality - throughput is bounded\n",
    "    - 100 requests a second\n",
    "    - must flush every 100 results and take the penalty\n",
    "    - if all results are saved at the end and issued all at once\n",
    "        - the server would only procress 100/time\n",
    "            - extra penalty\n",
    "- if throughput is so limited\n",
    "    - might as well run the serial code\n",
    "- pipelining - this mechanism of batching results\n",
    "    - can help tremendously "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Async"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- full async solution might be preferable\n",
    "- if CPU task is part of a larger I/O bound program - such as an HTTP server\n",
    "- if an API service, in response to some of its end points has to perform heavy computations\n",
    "    - we still want the API to be able to handle concurrent requests and be performant\n",
    "    - we also want the CPU task to run quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result_aiohttp(client_session):\n",
    "    sem = asyncio.Semaphore(100)\n",
    "\n",
    "    async def saver(result):\n",
    "        nonlocal sem, client_session\n",
    "        url = URL\n",
    "        async with sem:\n",
    "            async with client_session.post(url, data=result) as response:\n",
    "                return await response.json()\n",
    "\n",
    "    return saver\n",
    "\n",
    "async def calculate_task_aiohttp(num_iter, task_difficulty):\n",
    "    tasks = []\n",
    "    async with aiohttp.ClientSession() as client_session:\n",
    "        saver = save_result_aiohttp(client_session)\n",
    "        for _ in range(num_iter):\n",
    "            result = do_task(task_difficulty)\n",
    "            # instead of await db save immediately\n",
    "            # queue it into the event loop using asyncio.create_task\n",
    "            task = asyncio.create_task(saver(result))\n",
    "            tasks.append(task)\n",
    "            # we pause the main function to allow the event loop to take care of any pending tasks\n",
    "            # in general, this happens every time when an await statement is run\n",
    "            # but we generally don't await in CPU-bound code\n",
    "            # so we need a way to force the function to defer execution to the event loop\n",
    "            # try to issue it at any loop that we expect to iterate every 50-100 ms \n",
    "            await asyncio.sleep(0)\n",
    "        # wait for any tasks that haven't completed yet\n",
    "        await asyncio.wait(tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
